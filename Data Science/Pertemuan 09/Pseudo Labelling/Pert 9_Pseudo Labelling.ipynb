{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2n4knI7s0tdo","executionInfo":{"status":"ok","timestamp":1660878937912,"user_tz":-420,"elapsed":1620,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.preprocessing import LabelEncoder "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oQKyYNPo0tdr","executionInfo":{"status":"ok","timestamp":1660878937913,"user_tz":-420,"elapsed":18,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[],"source":["train = pd.read_csv('Train.csv')\n","test = pd.read_csv('Test.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"biPqYr4l0tdt","outputId":"5c54d8ff-1043-42d0-cb80-8e3007b32f36","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660878937914,"user_tz":-420,"elapsed":18,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"]}],"source":["# preprocessing\n","\n","### mean imputations \n","train['Item_Weight'].fillna((train['Item_Weight'].mean()), inplace=True)\n","test['Item_Weight'].fillna((test['Item_Weight'].mean()), inplace=True)\n","\n","### reducing fat content to only two categories \n","train['Item_Fat_Content'] = train['Item_Fat_Content'].replace(['low fat','LF'], ['Low Fat','Low Fat']) \n","train['Item_Fat_Content'] = train['Item_Fat_Content'].replace(['reg'], ['Regular']) \n","test['Item_Fat_Content'] = test['Item_Fat_Content'].replace(['low fat','LF'], ['Low Fat','Low Fat']) \n","test['Item_Fat_Content'] = test['Item_Fat_Content'].replace(['reg'], ['Regular'])\n","\n","## for calculating establishment year\n","train['Outlet_Establishment_Year'] = 2013 - train['Outlet_Establishment_Year'] \n","test['Outlet_Establishment_Year'] = 2013 - test['Outlet_Establishment_Year'] \n","\n","### missing values for size\n","train['Outlet_Size'].fillna('Small',inplace=True)\n","test['Outlet_Size'].fillna('Small',inplace=True)\n","\n","### label encoding cate. var.\n","col = ['Outlet_Size','Outlet_Location_Type','Outlet_Type','Item_Fat_Content']\n","test['Item_Outlet_Sales'] = 0\n","combi = train.append(test)\n","number = LabelEncoder()\n","for i in col:\n","    combi[i] = number.fit_transform(combi[i].astype('str'))\n","    combi[i] = combi[i].astype('int')\n","train = combi[:train.shape[0]]\n","test = combi[train.shape[0]:]\n","test.drop('Item_Outlet_Sales',axis=1,inplace=True)\n","\n","## removing id variables \n","training = train.drop(['Outlet_Identifier','Item_Type','Item_Identifier'],axis=1)\n","testing = test.drop(['Outlet_Identifier','Item_Type','Item_Identifier'],axis=1)\n","y_train = training['Item_Outlet_Sales']\n","training.drop('Item_Outlet_Sales',axis=1,inplace=True)\n","\n","features = training.columns\n","target = 'Item_Outlet_Sales'\n","\n","X_train, X_test = training, testing"]},{"cell_type":"markdown","metadata":{"id":"rAJI4UVt0tdx"},"source":["# Model exploration"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"y6pVCXL40tdy","executionInfo":{"status":"ok","timestamp":1660878938269,"user_tz":-420,"elapsed":367,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[],"source":["from xgboost import XGBRegressor\n","from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n","#from sklearn.neural_network import MLPRegressor\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4RKXaFtA0td1","outputId":"1e874525-5652-41b6-82e1-2b86b94c7a51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660878959632,"user_tz":-420,"elapsed":21368,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["RandomForestRegressor     CV-5 RMSE:  1148.35 (+/- 14834.59)\n","[03:12:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[03:12:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[03:12:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","XGBRegressor              CV-5 RMSE:  1084.86 (+/- 26774.60)\n","Ridge                     CV-5 RMSE:  1206.41 (+/- 54020.12)\n","BayesianRidge             CV-5 RMSE:  1206.56 (+/- 52695.34)\n","ExtraTreesRegressor       CV-5 RMSE:  1190.90 (+/- 30676.48)\n","ElasticNet                CV-5 RMSE:  1259.18 (+/- 89803.16)\n","KNeighborsRegressor       CV-5 RMSE:  1245.71 (+/- 37275.84)\n","GradientBoostingRegressor CV-5 RMSE:  1086.33 (+/- 19375.06)\n"]}],"source":["model_factory = [\n","    RandomForestRegressor(),\n","    XGBRegressor(nthread=1),\n","    #MLPRegressor(),\n","    Ridge(),\n","    BayesianRidge(),\n","    ExtraTreesRegressor(),\n","    ElasticNet(),\n","    KNeighborsRegressor(),\n","    GradientBoostingRegressor()\n","]\n","\n","for model in model_factory:\n","    model.seed = 42\n","    num_folds = 3\n","\n","    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error')\n","    score_description = \" %0.2f (+/- %0.2f)\" % (np.sqrt(scores.mean()*-1), scores.std() * 2)\n","\n","    print('{model:25} CV-5 RMSE: {score}'.format(\n","        model=model.__class__.__name__,\n","        score=score_description\n","    ))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IZ1vW2DI0td4","outputId":"ffeb18b2-470a-436c-ef50-768d799920f0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660878965417,"user_tz":-420,"elapsed":5832,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[03:12:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([-1195820.49498294, -1168271.94483247, -1166641.76380863])"]},"metadata":{},"execution_count":6}],"source":["## normal submission using xgb\n","model = XGBRegressor()\n","model.fit(X_train,y_train)\n","pred = model.predict(X_test)\n","\n","## saving file\n","sub = pd.DataFrame(data = pred, columns=['Item_Outlet_Sales'])\n","sub['Item_Identifier'] = test['Item_Identifier']\n","sub['Outlet_Identifier'] = test['Outlet_Identifier']\n","#sub.to_csv('bigmart-xgb.csv', index='False')\n","\n","cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error', n_jobs=8)"]},{"cell_type":"markdown","metadata":{"id":"aYnYJRVE0td5"},"source":["Xgb gives us the best results. on submission it gives an rmse of 1152.73"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":true,"id":"GYGgII900td7","executionInfo":{"status":"ok","timestamp":1660878965419,"user_tz":-420,"elapsed":20,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[],"source":["from sklearn.utils import shuffle\n","from sklearn.base import BaseEstimator, RegressorMixin\n","\n","class PseudoLabeler(BaseEstimator, RegressorMixin):\n","    '''\n","    Sci-kit learn wrapper for creating pseudo-lebeled estimators.\n","    '''\n","    \n","    def __init__(self, model, unlabled_data, features, target, sample_rate=0.2, seed=42):\n","        '''\n","        @sample_rate - percent of samples used as pseudo-labelled data\n","                       from the unlabled dataset\n","        '''\n","        assert sample_rate <= 1.0, 'Sample_rate should be between 0.0 and 1.0.'\n","        \n","        self.sample_rate = sample_rate\n","        self.seed = seed\n","        self.model = model\n","        self.model.seed = seed\n","        \n","        self.unlabled_data = unlabled_data\n","        self.features = features\n","        self.target = target\n","        \n","    def get_params(self, deep=True):\n","        return {\n","            \"sample_rate\": self.sample_rate,\n","            \"seed\": self.seed,\n","            \"model\": self.model,\n","            \"unlabled_data\": self.unlabled_data,\n","            \"features\": self.features,\n","            \"target\": self.target\n","        }\n","\n","    def set_params(self, **parameters):\n","        for parameter, value in parameters.items():\n","            setattr(self, parameter, value)\n","        return self\n","\n","        \n","    def fit(self, X, y):\n","        '''\n","        Fit the data using pseudo labeling.\n","        '''\n","\n","        augemented_train = self.__create_augmented_train(X, y)\n","        self.model.fit(\n","            augemented_train[self.features],\n","            augemented_train[self.target]\n","        )\n","        \n","        return self\n","\n","\n","    def __create_augmented_train(self, X, y):\n","        '''\n","        Create and return the augmented_train set that consists\n","        of pseudo-labeled and labeled data.\n","        '''        \n","        num_of_samples = int(len(self.unlabled_data) * self.sample_rate)\n","        \n","        # Train the model and creat the pseudo-labels\n","        self.model.fit(X, y)\n","        pseudo_labels = self.model.predict(self.unlabled_data[self.features])\n","        \n","        # Add the pseudo-labels to the test set\n","        pseudo_data = self.unlabled_data.copy(deep=True)\n","        pseudo_data[self.target] = pseudo_labels\n","        \n","        # Take a subset of the test set with pseudo-labels and append in onto\n","        # the training set\n","        sampled_pseudo_data = pseudo_data.sample(n=num_of_samples)\n","        temp_train = pd.concat([X, y], axis=1)\n","        augemented_train = pd.concat([sampled_pseudo_data, temp_train])\n","\n","        return shuffle(augemented_train)\n","        \n","    def predict(self, X):\n","        '''\n","        Returns the predicted values.\n","        '''\n","        return self.model.predict(X)\n","    \n","    def get_model_name(self):\n","        return self.model.__class__.__name__"]},{"cell_type":"markdown","metadata":{"id":"yIDJxSQL0td-"},"source":["# Pseudo Labeler"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"KUfJBklg0td_","outputId":"e6fb9894-a997-4e0c-ca02-68a2a2d86df8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660878972543,"user_tz":-420,"elapsed":7140,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[03:12:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[03:12:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"]},{"output_type":"execute_result","data":{"text/plain":["array([-1188572.57635194, -1164640.20470867, -1162726.80343378])"]},"metadata":{},"execution_count":8}],"source":["model = PseudoLabeler(\n","    XGBRegressor(nthread=1),\n","    test,\n","    features,\n","    target,\n","    sample_rate = 0.3\n",")\n","\n","model.fit(X_train, y_train)\n","pred = model.predict(X_test)\n","cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error', n_jobs=8)"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"id":"noL7ntTN0teA","executionInfo":{"status":"ok","timestamp":1660878972544,"user_tz":-420,"elapsed":9,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[],"source":["sub = pd.DataFrame(data = pred, columns=['Item_Outlet_Sales'])\n","sub['Item_Identifier'] = test['Item_Identifier']\n","sub['Outlet_Identifier'] = test['Outlet_Identifier']\n","sub.to_csv('pseudo-labelling.csv', index='False')"]},{"cell_type":"markdown","metadata":{"id":"j037nTIa0teC"},"source":["On submission, it gives a rmse score of 1151.38 which is better than our previous xgb submission."]},{"cell_type":"markdown","metadata":{"id":"oYROgMg70teC"},"source":["# Comparing xgboost with xgb with pseudo labelling"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"cYkFmnAP0teD","outputId":"a1a384a3-9a8c-400e-d43c-9f7805173041","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660878985697,"user_tz":-420,"elapsed":13161,"user":{"displayName":"Dewa Ayu","userId":"02880960379062867740"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["XGBRegressor              CV-8 MSE: 1083.2088 (+/- 122498.1182)\n","PseudoLabeler             CV-8 MSE: 1082.0611 (+/- 128381.9845)\n"]}],"source":["model_factory = [\n","    XGBRegressor(nthread=1),\n","    \n","    PseudoLabeler(\n","        XGBRegressor(nthread=1),\n","        test,\n","        features,\n","        target,\n","        sample_rate=0.3\n","    ),\n","]\n","\n","for model in model_factory:\n","    model.seed = 42\n","    num_folds = 8\n","    \n","    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error', n_jobs=8)\n","    score_description = \"MSE: %0.4f (+/- %0.4f)\" % (np.sqrt(scores.mean()*-1), scores.std() * 2)\n","\n","    print('{model:25} CV-{num_folds} {score_cv}'.format(\n","        model=model.__class__.__name__,\n","        num_folds=num_folds,\n","        score_cv=score_description\n","    ))"]},{"cell_type":"markdown","metadata":{"id":"ZcOdObIJ0teE"},"source":["# Performance of pseudo-labelling depedendance on sampling rate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu2H5jfe0teF","outputId":"db5f81cf-8134-45f3-d591-1ecc1f98042e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["RandomForestRegressor\n","XGBRegressor\n"]}],"source":["sample_rates = np.linspace(0, 1, 10)\n","\n","def pseudo_label_wrapper(model):\n","    return PseudoLabeler(model, test, features, target)\n","\n","# List of all models to test\n","model_factory = [\n","    RandomForestRegressor(n_jobs=1),\n","    XGBRegressor(),\n","]\n","\n","# Apply the PseudoLabeler class to each model\n","model_factory = map(pseudo_label_wrapper, model_factory)\n","\n","# Train each model with different sample rates\n","results = {}\n","num_folds = 5\n","\n","for model in model_factory:\n","    model_name = model.get_model_name()\n","    print('%s' % model_name)\n","\n","    results[model_name] = list()\n","    for sample_rate in sample_rates:\n","        model.sample_rate = sample_rate\n","        \n","        # Calculate the CV-3 R2 score and store it\n","        scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error', n_jobs=8)\n","        results[model_name].append(np.sqrt(scores.mean()*-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWinh3xR0teG"},"outputs":[],"source":["plt.figure(figsize=(16, 18))\n","\n","i = 1\n","for model_name, performance in results.items():    \n","    plt.subplot(3, 3, i)\n","    i += 1\n","    \n","    plt.plot(sample_rates, performance)\n","    plt.title(model_name)\n","    plt.xlabel('sample_rate')\n","    plt.ylabel('RMSE')\n","    \n","\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Pert 9_Pseudo Labelling.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}